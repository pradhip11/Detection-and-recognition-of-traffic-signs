{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kjxVaXhzm_fw",
        "OjRANvafnOmd",
        "1Yzv8pEuoMYM",
        "lodUImYuoQJP",
        "LtfpeGfvoWQs"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prequisite Tasks"
      ],
      "metadata": {
        "id": "kjxVaXhzm_fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the Training dataset from it's source to Collab\n",
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip"
      ],
      "metadata": {
        "id": "z4GbcuGLog0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the Training dataset \n",
        "!unzip GTSRB_Final_Training_Images.zip"
      ],
      "metadata": {
        "id": "FgV1MKOdomRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the Test dataset from it's source to Collab\n",
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n"
      ],
      "metadata": {
        "id": "OB-NlAd2oqOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the Test dataset \n",
        "!unzip GTSRB_Final_Test_Images.zip"
      ],
      "metadata": {
        "id": "PVWZP3_wo0ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the information related to Test data from it's source to Collab\n",
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip"
      ],
      "metadata": {
        "id": "8ZQwNCh9o7wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the information regarding the categories in Test dataset.\n",
        "!unzip GTSRB_Final_Test_GT.zip"
      ],
      "metadata": {
        "id": "IpQt0LebpEYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary imports and setup: "
      ],
      "metadata": {
        "id": "bJPMMjBrpm7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import os.path as path\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers \n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "from skimage import transform,io,color,exposure\n",
        "from random import shuffle\n",
        "np.random.seed(42)\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical    \n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "lJq9U1tHpvwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the dataset path in Collab.\n",
        "\n",
        "data_path = '/content/GTSRB'\n",
        "train_path = '/content/GTSRB/Final_Training/Images'\n",
        "test_path = '/content/GTSRB/Final_Test/Images'"
      ],
      "metadata": {
        "id": "V4vSyuVzqA1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Names for each of the 43 categories in order:\n",
        "\n",
        "category_names = [\n",
        "    'Speed limit (20km/h)',\n",
        "    'Speed limit (30km/h)',\n",
        "    'Speed limit (50km/h)',\n",
        "    'Speed limit (60km/h)',\n",
        "    'Speed limit (70km/h)',\n",
        "    'Speed limit (80km/h)',\n",
        "    'End of speed limit (80km/h)',\n",
        "    'Speed limit (100km/h)',\n",
        "    'Speed limit (120km/h)',\n",
        "    'No passing',\n",
        "    'No passing for vehicles over 3.5 metric tons',\n",
        "    'Right-of-way at the next intersection',\n",
        "    'Priority road',\n",
        "    'Yield',\n",
        "    'Stop',\n",
        "    'No vehicles',\n",
        "    'Vehicles over 3.5 metric tons prohibited',\n",
        "    'No entry',\n",
        "    'General caution',\n",
        "    'Dangerous curve to the left',\n",
        "    'Dangerous curve to the right',\n",
        "    'Double curve',\n",
        "    'Bumpy road',\n",
        "    'Slippery road',\n",
        "    'Road narrows on the right',\n",
        "    'Road work',\n",
        "    'Traffic signals',\n",
        "    'Pedestrians',\n",
        "    'Children crossing',\n",
        "    'Bicycles crossing',\n",
        "    'Beware of ice/snow',\n",
        "    'Wild animals crossing',\n",
        "    'End of all speed and passing limits',\n",
        "    'Turn right ahead',\n",
        "    'Turn left ahead',\n",
        "    'Ahead only',\n",
        "    'Go straight or right',\n",
        "    'Go straight or left',\n",
        "    'Keep right',\n",
        "    'Keep left',\n",
        "    'Roundabout mandatory',\n",
        "    'End of no passing',\n",
        "    'End of no passing by vehicles over 3.5 metric tons'\n",
        "]"
      ],
      "metadata": {
        "id": "wuOrLWpoiNMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive Analysis"
      ],
      "metadata": {
        "id": "OjRANvafnOmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary sign_data is initialized to store the number of files in each class (folder).\n",
        "\n",
        "train_folder = os.listdir(train_path)\n",
        "# Dictionary which has {class_name : file in each class}\n",
        "# Used to visualize the data\n",
        "sign_data = {}\n",
        "\n",
        "for f in train_folder:\n",
        "  train_files = os.listdir(train_path + '/' + f)\n",
        "  # Length - 1 so we dont consider the .csv file in each folder\n",
        "  class_len = len(train_files) - 1\n",
        "  class_name = str(f)\n",
        "  sign_data.update({class_name : class_len})\n",
        "  \n",
        "# Convert the dict to df for further use\n",
        "df_class = pd.DataFrame.from_dict(sign_data, orient = 'index', columns = ['Total Count'])\n",
        "df_class = df_class.sort_index()"
      ],
      "metadata": {
        "id": "DeSuEHH-i96-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Total number of images in Train and Test dataset"
      ],
      "metadata": {
        "id": "47NqZ-hTjSvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_len = len(os.listdir(train_path))\n",
        "train_len = df_class['Total Count'].sum()\n",
        "test_len = len(os.listdir(test_path))\n",
        "\n",
        "print(f'Total # of Sign Classfication - {class_len}.\\nTrain Images - {train_len}\\nTest Images - {test_len}')"
      ],
      "metadata": {
        "id": "FXBwTfXVjWaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Read the csv file in each training class and convert it into dataframe for training set."
      ],
      "metadata": {
        "id": "IoLSz9ZHjekP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = [ train_path +'/' + f1 + '/' + f2 for f1 in os.listdir(train_path) \n",
        "            for f2 in os.listdir(train_path + '/' + f1) if f2.endswith('.csv')]\n",
        "train_csv.sort()\n",
        "\n",
        "df_traincsv = pd.DataFrame()\n",
        "for csv in train_csv:\n",
        "  df_temp = pd.read_csv(csv, sep = ';')\n",
        "  frames = [df_traincsv, df_temp]\n",
        "  df_traincsv = pd.concat(frames)\n",
        "\n",
        "print(df_traincsv.shape)\n",
        "df_traincsv.head()"
      ],
      "metadata": {
        "id": "WFDYkiP7jf64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Read the csv file in test image folder and convert it into dataframe for test set."
      ],
      "metadata": {
        "id": "33N4zjcQj4iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_csv = [test_path + '/' + f for f in os.listdir(test_path) if f.endswith('.csv')]\n",
        "test_csv = '/content/GT-final_test.csv'\n",
        "df_testcsv = pd.read_csv(test_csv, sep = ';')\n",
        "print(df_testcsv.shape)\n",
        "df_testcsv.head()"
      ],
      "metadata": {
        "id": "0hBUwAfsj5uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. (a) Analysis for Training dataset."
      ],
      "metadata": {
        "id": "smvJ6VnVkGK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplot to show the number of images per category in the training dataset. "
      ],
      "metadata": {
        "id": "YcDAwqKVkYDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of pictures in each category\n",
        "category_counts = df_traincsv['ClassId'].value_counts().sort_values()\n",
        "sorted_categories = [category_names[i] for i in category_counts.index]\n",
        "# create a bar plot using seaborn\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.figure(figsize=(13,13))\n",
        "sns.countplot(y='ClassId', data=df_traincsv, order=category_counts.index)\n",
        "plt.yticks(range(len(category_names)), sorted_categories)\n",
        "plt.xlabel('Number of Pictures')\n",
        "plt.ylabel('Category Names')\n",
        "plt.title('Number of Pictures in each Category')\n",
        "# adjust the spacing\n",
        "plt.subplots_adjust(left=0.25, right=0.9, top=0.9, bottom=0.1)\n",
        "\n",
        "# adjust the font size\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('axes', labelsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9kP0g4kYkZa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Width and Height distribution of images in training set"
      ],
      "metadata": {
        "id": "l6BP49FXkhYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(20,5))\n",
        "sns.histplot(data = df_traincsv, x = df_traincsv['Width'],  binwidth = 10,  color = 'orange',  kde= True,ax = ax1)\n",
        "sns.histplot(data = df_traincsv, x = df_traincsv['Height'],  binwidth = 10, color = 'magenta', kde= True, ax = ax2)\n",
        "ax1.set_title('Width Distribution - Train')\n",
        "ax2.set_title('Height Distribution - Train')"
      ],
      "metadata": {
        "id": "md2oO23bkh8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The width distribution of pictures per category in training set:"
      ],
      "metadata": {
        "id": "kN8R0cgikrvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of pictures in each category\n",
        "category_counts = df_traincsv['ClassId'].value_counts().sort_values()\n",
        "\n",
        "# Create a figure with subplots for each category\n",
        "nrows = (len(category_counts) - 1) // 5 + 1\n",
        "ncols = min(len(category_counts), 5)\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, nrows*6))\n",
        "\n",
        "# Loop over each category that has data\n",
        "for i, category in enumerate(category_counts.index):\n",
        "    # Get the subset of data for the current category\n",
        "    category_df = df_traincsv[df_traincsv['ClassId'] == category]\n",
        "    \n",
        "    # Plot the distribution of widths\n",
        "    sns.histplot(data=category_df, x=\"Width\", stat=\"count\", ax=axes[i//ncols, i%ncols])\n",
        "    axes[i//ncols, i%ncols].set_xlabel('Count')\n",
        "    axes[i//ncols, i%ncols].set_ylabel('Width')\n",
        "    axes[i//ncols, i%ncols].set_title(category_names[category])\n",
        "\n",
        "# Remove empty subplots\n",
        "for j in range(len(category_counts), nrows*ncols):\n",
        "    fig.delaxes(axes[j//ncols, j%ncols])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GgD84e2dkuJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. (b) Analysis for test dataset:"
      ],
      "metadata": {
        "id": "iE31eOoukz-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplot to show the number of images per category in the test dataset. "
      ],
      "metadata": {
        "id": "tR8spEEKk5kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of pictures in each category\n",
        "category_counts = df_testcsv['ClassId'].value_counts().sort_values()\n",
        "sorted_categories = [category_names[i] for i in category_counts.index]\n",
        "# create a bar plot using seaborn\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.figure(figsize=(13,13))\n",
        "sns.countplot(y='ClassId', data=df_testcsv, order=category_counts.index)\n",
        "plt.yticks(range(len(category_names)), sorted_categories)\n",
        "plt.xlabel('Number of Pictures')\n",
        "plt.ylabel('Category Names')\n",
        "plt.title('Number of Pictures in each Category - TEST')\n",
        "# adjust the spacing\n",
        "plt.subplots_adjust(left=0.25, right=0.9, top=0.9, bottom=0.1)\n",
        "\n",
        "# adjust the font size\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('axes', labelsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A3sWLwEklE8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Width and Height distribution of images in testset"
      ],
      "metadata": {
        "id": "d09DhpzxlHwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(20,5))\n",
        "sns.histplot(data = df_testcsv, x = df_testcsv['Width'],  binwidth = 10,  color = 'r',  kde= True,ax = ax1)\n",
        "sns.histplot(data = df_testcsv, x = df_testcsv['Height'],  binwidth = 10, color = 'gold', kde= True, ax = ax2)\n",
        "ax1.set_title('Width Distribution - Test')\n",
        "ax2.set_title('Height Distribution - Test')"
      ],
      "metadata": {
        "id": "tKms-KyQlMC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Display random images from the train set"
      ],
      "metadata": {
        "id": "4ALUuvUJlOvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common method to plot images based on flag\n",
        "# flag = img -> img file is passed\n",
        "# flag = np -> np array is passed\n",
        "# tot_img = actual img required + 1\n",
        "def plt_img(img_list,tot_img, flag = 'img'):\n",
        "  plt.figure(figsize=(50,50))\n",
        "  for i in range(1,tot_img):\n",
        "    plt.subplot(5,5,i)\n",
        "    if flag == 'img':\n",
        "       #r_i = random.choice(img_list)\n",
        "       r_img = imread(img_list[i-1])\n",
        "       plt.imshow(r_img)\n",
        "    elif flag == 'np':\n",
        "        img = X_train[list_index[i-1]]\n",
        "        plt.imshow(img , interpolation='nearest', cmap= 'gray')  \n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "h5HUhMkUlkle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = [ train_path +'/' + f1 + '/' + f2 for f1 in os.listdir(train_path) \n",
        "            for f2 in os.listdir(train_path + '/' + f1) if f2.endswith('.ppm')]\n",
        "train_img.sort()"
      ],
      "metadata": {
        "id": "jR0s8imUlsLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rimg = [random.choice(train_img) for i in range(0,25)]\n",
        "plt_img(train_rimg,26)"
      ],
      "metadata": {
        "id": "ma9hyHHRltpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Display random images from the test set"
      ],
      "metadata": {
        "id": "6PDEr8iklwSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = [ test_path +'/' + f1 for f1 in os.listdir(test_path) if f1.endswith('.ppm')]\n",
        "test_img.sort()"
      ],
      "metadata": {
        "id": "P6wYSaGulycI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_rimg = [random.choice(test_img) for i in range(0,25)]\n",
        "plt_img(test_rimg,26)"
      ],
      "metadata": {
        "id": "YfVEKBbHl03h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1Yzv8pEuoMYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Resize images to a fixed size, apply other preprocessing like grayscaling, histogram equalization and normalization for Training data."
      ],
      "metadata": {
        "id": "fyy547pcmFmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the folder names located in the training data\n",
        "train_folder = [folder for folder in os.listdir(train_path)]\n",
        "train_folder.sort()"
      ],
      "metadata": {
        "id": "CzZUxTyYmGQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to run ~1m5s\n",
        "img_width = 32\n",
        "img_height = 32\n",
        "img_preprocessed = []\n",
        "img_err = []\n",
        "\n",
        "for folder_name in train_folder:\n",
        "  img_folder = train_path + '/' + folder_name\n",
        "  for img_file in os.listdir(img_folder):\n",
        "    img_path = img_folder + '/' + img_file\n",
        "    if img_path.endswith('.ppm'):\n",
        "      try:\n",
        "        img = io.imread(img_path)\n",
        "        gray_img = color.rgb2gray(img)\n",
        "        gray_img = exposure.equalize_hist(gray_img)\n",
        "        img_resize = transform.resize(gray_img, (img_width, img_height))\n",
        "        img = tf.keras.utils.normalize(img_resize,axis=1)\n",
        "        img_preprocessed.append([img, folder_name])\n",
        "      except Exception:\n",
        "        img_err.append([img, folder_name])\n"
      ],
      "metadata": {
        "id": "qzUwU2nlmKax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the preprecoessed image data\n",
        "shuffle(img_preprocessed)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for image,classid in img_preprocessed:\n",
        "  X_train.append(image)\n",
        "  y_train.append(classid)"
      ],
      "metadata": {
        "id": "KziVifVkmNnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Display the preprocessed images"
      ],
      "metadata": {
        "id": "r5gCWF9qmSrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_index = [train_img.index(i) for i in train_rimg]\n",
        "plt_img(None,11,'np')"
      ],
      "metadata": {
        "id": "s4NvFnMxmTel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Reshape the X_train to gray channel"
      ],
      "metadata": {
        "id": "ZgzQmlr1mXLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_array = np.array(X_train)\n",
        "X_train = X_array.reshape(-1,img_width,img_height,1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(f'Shape of X {X_train.shape}.\\nShape of y {y_train.shape}')\n"
      ],
      "metadata": {
        "id": "bihPzoGSmX1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Preprocessing for test data to fit the model."
      ],
      "metadata": {
        "id": "QQbv6C4zmqEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to exe ~37s\n",
        "img_width = 32\n",
        "img_height = 32\n",
        "img_test_pre = []\n",
        "img_test_err = []\n",
        "\n",
        "for img in os.listdir(test_path):\n",
        "  img_path = test_path +'/' + img\n",
        "  if img_path.endswith('.ppm'):\n",
        "     try:\n",
        "        classid = df_testcsv[df_testcsv['Filename'] == img]['ClassId'].item()\n",
        "        classid = str(classid)\n",
        "        classid = '0000' + classid if len(classid) == 1 else '000' + classid\n",
        "        img_i = io.imread(img_path)\n",
        "        gray_img = color.rgb2gray(img_i)\n",
        "        gray_img = exposure.equalize_hist(gray_img)\n",
        "        img_resize = transform.resize(gray_img, (img_width, img_height))\n",
        "        img = tf.keras.utils.normalize(img_resize,axis=1)\n",
        "        img_test_pre.append([img, classid])\n",
        "     except Exception as exp:\n",
        "        img_test_err.append([img, folder_name])"
      ],
      "metadata": {
        "id": "L9W-Ignwm1-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the preprecoessed image data\n",
        "shuffle(img_test_pre)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for image,classid in img_test_pre:\n",
        "  X_test.append(image)\n",
        "  y_test.append(classid)\n",
        "\n"
      ],
      "metadata": {
        "id": "VSQHMLLynE1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Arranging preprocessed data so it can fit the model accurately."
      ],
      "metadata": {
        "id": "JRqJeYSXnQ0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_arr = np.array(X_test)\n",
        "X_test = X_arr.reshape(-1,img_width,img_height,1)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(f'Shape of X {X_test.shape}.\\nShape of y {y_test.shape}')"
      ],
      "metadata": {
        "id": "9dBcfvCxnqre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "XrGQuEsUn1nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation"
      ],
      "metadata": {
        "id": "lodUImYuoQJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Neural Network Implemetation"
      ],
      "metadata": {
        "id": "Y-It9sOsn7hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu'))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=\"adam\", \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dwklNGWHoBil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5Y5yRNCKoGH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to exe ~7m\n",
        "batch_size = 64\n",
        "epoch = 10\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epoch, \n",
        "                    validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "YEcqpgPooIfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result And Analysis"
      ],
      "metadata": {
        "id": "LtfpeGfvoWQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Model Evaluation"
      ],
      "metadata": {
        "id": "Oam0KaKLoRw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_history = pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "XkayYcDkoXKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(20,5))\n",
        "sns.lineplot(data = df_history[['accuracy','val_accuracy']], palette = 'hot_r', ax = ax1)\n",
        "sns.lineplot(data = df_history[['loss','val_loss']],palette = 'hot_r', ax = ax2)\n",
        "ax1.set_title('Model Accuracy')\n",
        "ax2.set_title('Model Loss')\n",
        "ax1.set(xlabel='Epochs', ylabel='Accuracy')\n",
        "ax2.set(xlabel='Epochs', ylabel='Loss')\n",
        "ax1.grid()\n",
        "ax2.grid()"
      ],
      "metadata": {
        "id": "JEf_1DnXoYtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(figsize=(6,4))\n",
        "sns.lineplot(data = df_history,  palette = 'seismic', ax = ax)\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "lHUWrzNAobng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy of the model is {accuracy:.4f}.\\nLoss of the model is {loss:.4f}')"
      ],
      "metadata": {
        "id": "YXB29s9oonVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Image - Validation"
      ],
      "metadata": {
        "id": "fw_MshNgorXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data = []\n",
        "img_labels = df_testcsv['ClassId'].values\n",
        "img_name = df_testcsv['Filename'].values\n",
        "img_size = 32\n",
        "\n",
        "\n",
        "for img in img_name:\n",
        "  img_path = test_path +'/' + img\n",
        "  if img_path.endswith('.ppm'):\n",
        "     try:\n",
        "        img_i = io.imread(img_path)\n",
        "        gray_img = color.rgb2gray(img_i)\n",
        "        img_resize = transform.resize(gray_img, (img_width, img_height))\n",
        "        img_arr = img_resize.reshape(img_size, img_size, 1)\n",
        "        img_data.append(img_arr)\n",
        "     except Exception as exp:\n",
        "        print('Error occured!')\n",
        "\n",
        "X_test_pred =  np.array(img_data) \n",
        "pred = np.argmax(model.predict(X_test_pred),axis= -1)\n"
      ],
      "metadata": {
        "id": "NPtJDWiOosUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test Data accuracy: {accuracy_score(img_labels, pred)*100: .4f}')"
      ],
      "metadata": {
        "id": "b6cQ58tootxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "\n",
        "class_report = classification_report(img_labels, pred,output_dict=True)\n",
        "df_report = pd.DataFrame(class_report).transpose()\n",
        "df_report"
      ],
      "metadata": {
        "id": "AtN9wQxzovpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "conf_mat = confusion_matrix(img_labels, pred)\n",
        "df_conf = pd.DataFrame(conf_mat, index = category_names, columns = category_names )\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(df_conf, cmap = 'bone', fmt = '.2g', annot=True)"
      ],
      "metadata": {
        "id": "3Lp9Y9kcozWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly compare the predicted value along with ground truth\n",
        "plt.figure(figsize=(50,50))\n",
        "for i in range(1,26):\n",
        "  plt.subplot(5,5,i)\n",
        "  rand = random.randint(0,12000)\n",
        "  y_pred = pred[rand]\n",
        "  y = img_labels[rand]\n",
        "  col = 'g' if y == y_pred else 'r'\n",
        "  plt.title(f'Actual={y}  Pred={y_pred}', color = col,fontsize = 20)\n",
        "  plt.imshow(X_test_pred[rand], cmap = 'gray')"
      ],
      "metadata": {
        "id": "qXuKEF1ao2Zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}